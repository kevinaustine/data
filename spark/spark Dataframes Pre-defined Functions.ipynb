{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f569c7-ea4a-439f-b626-7048095c9aa0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions or APIs to process Data Frames.\n",
    "\n",
    "- Projection - **select** or **withColumn** or **drop** or **selectExpr**\n",
    "- Filtering - **filter** or **where**\n",
    "- Grouping data by key and perform aggregations - **groupBy**\n",
    "- Sorting data - **sort** or **orderBy**\n",
    "- We can pass column names or literals or expressions to all the Data Frame APIs.\n",
    "- Expressions include arithmetic operations, transformations using functions from pyspark.sql.functions.\n",
    "- There are approximately 300 functions under pyspark.sql.functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b119470a-0363-4dde-9c3f-94910bf04cda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "902b5f86-6280-43bb-ad13-1c9166dce739",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(' Python - Processing Column Data'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88579570-b83d-4fe9-8a90-574612d5bb8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading data\n",
    "orders = spark.read.csv(\n",
    "    '/data/retail_db/orders',\n",
    "    schema='order_id INT, order_date STRING, order_customer_id INT, order_status STRING'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddff685c-8da5-4845-b06a-30bac37754d4",
   "metadata": {},
   "source": [
    "#### Importing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d913991-2b87-4495-95d1-5fd73dc9a9a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format,current_date,current_timestamp,unix_timestamp,\\\n",
    "to_date,to_timestamp,from_unixtime,date_add,date_sub,datediff,months_between,add_months,trunc,date_trunc,\\\n",
    "year, month, weekofyear, dayofmonth,dayofyear, dayofweek, current_date,hour, minute, second,\\\n",
    "upper,concat,lower,initcap,length,substring,split,explode,lpad,rpad,trim,round,\\\n",
    "coalesce,lit,col,expr,when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06c63f3-ca31-4bf3-a97f-592dce80181c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfeaccce-2a89-4e0a-b94b-72f731aae32b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------------+---------------+\n",
      "|order_id|          order_date|order_customer_id|   order_status|\n",
      "+--------+--------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:...|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:...|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:...|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:...|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:...|            11318|       COMPLETE|\n",
      "+--------+--------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85b1f4a2-78cb-4f93-920a-2bf4bbdd113d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- order_customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "343bc059-fe69-46a7-b614-b4b3661b6fd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------------+---------------+-----------+\n",
      "|order_id|          order_date|order_customer_id|   order_status|order_month|\n",
      "+--------+--------------------+-----------------+---------------+-----------+\n",
      "|       1|2013-07-25 00:00:...|            11599|         CLOSED|     201307|\n",
      "|       2|2013-07-25 00:00:...|              256|PENDING_PAYMENT|     201307|\n",
      "|       3|2013-07-25 00:00:...|            12111|       COMPLETE|     201307|\n",
      "|       4|2013-07-25 00:00:...|             8827|         CLOSED|     201307|\n",
      "|       5|2013-07-25 00:00:...|            11318|       COMPLETE|     201307|\n",
      "+--------+--------------------+-----------------+---------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function as part of projections\n",
    "\n",
    "orders.select('*', date_format('order_date', 'yyyyMM').alias('order_month')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c768d911-5995-4050-a2d4-fb80af492e88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------------+---------------+-----------+\n",
      "|order_id|          order_date|order_customer_id|   order_status|order_month|\n",
      "+--------+--------------------+-----------------+---------------+-----------+\n",
      "|       1|2013-07-25 00:00:...|            11599|         CLOSED|     201307|\n",
      "|       2|2013-07-25 00:00:...|              256|PENDING_PAYMENT|     201307|\n",
      "|       3|2013-07-25 00:00:...|            12111|       COMPLETE|     201307|\n",
      "|       4|2013-07-25 00:00:...|             8827|         CLOSED|     201307|\n",
      "|       5|2013-07-25 00:00:...|            11318|       COMPLETE|     201307|\n",
      "+--------+--------------------+-----------------+---------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.withColumn('order_month', date_format('order_date', 'yyyyMM')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e86b50a-0a7d-477e-8239-29f98cb3c81e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+-----------------+---------------+\n",
      "|order_id|order_date           |order_customer_id|order_status   |\n",
      "+--------+---------------------+-----------------+---------------+\n",
      "|25876   |2014-01-01 00:00:00.0|3414             |PENDING_PAYMENT|\n",
      "|25877   |2014-01-01 00:00:00.0|5549             |PENDING_PAYMENT|\n",
      "|25878   |2014-01-01 00:00:00.0|9084             |PENDING        |\n",
      "|25879   |2014-01-01 00:00:00.0|5118             |PENDING        |\n",
      "|25880   |2014-01-01 00:00:00.0|10146            |CANCELED       |\n",
      "+--------+---------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function as part of where or filter\n",
    "\n",
    "orders. \\\n",
    "    filter(date_format('order_date', 'yyyyMM') == 201401). \\\n",
    "    show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e49d2b4-41d2-499b-b950-88012362d732",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|order_month|count|\n",
      "+-----------+-----+\n",
      "|     201401| 5908|\n",
      "|     201405| 5467|\n",
      "|     201312| 5892|\n",
      "|     201310| 5335|\n",
      "|     201311| 6381|\n",
      "+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function as part of groupBy\n",
    "orders. \\\n",
    "    groupBy(date_format('order_date', 'yyyyMM').alias('order_month')). \\\n",
    "    count(). \\\n",
    "    show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0fc400-881a-4c35-9195-7d79ee87282c",
   "metadata": {},
   "source": [
    "create data frame using dummy data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aed0187a-1cc2-45f8-afa9-00ba70a7da4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Oracle dual (view)\n",
    "# dual - dummy CHAR(1)\n",
    "# \"X\" - One record\n",
    "l = [('X', )]\n",
    "df = spark.createDataFrame(l, \"dummy STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52b0be4b-6784-4714-9ec3-bb163669d481",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dummy: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98c021c9-c050-4924-97ad-506854fcbea4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|dummy|\n",
      "+-----+\n",
      "|    X|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cfd971f-f14d-43a6-8391-61447e184116",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|current_date()|\n",
      "+--------------+\n",
      "|    2023-04-15|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(current_date()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2d79947-2b5b-4519-80c3-a124a57bab36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|current_date|\n",
      "+------------+\n",
      "|  2023-04-15|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(current_date().alias(\"current_date\")). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58561ce8-23d9-4014-8201-36adac283417",
   "metadata": {},
   "source": [
    "creating Data Frame using collection of employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a8099f4-ccb7-4b9f-96ef-3854bcc9b9f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employees = [\n",
    "    (1, \"Scott\", \"Tiger\", 1000.0, \n",
    "      \"united states\", \"+1 123 456 7890\", \"123 45 6789\"\n",
    "    ),\n",
    "     (2, \"Henry\", \"Ford\", 1250.0, \n",
    "      \"India\", \"+91 234 567 8901\", \"456 78 9123\"\n",
    "     ),\n",
    "     (3, \"Nick\", \"Junior\", 750.0, \n",
    "      \"united KINGDOM\", \"+44 111 111 1111\", \"222 33 4444\"\n",
    "     ),\n",
    "     (4, \"Bill\", \"Gomes\", 1500.0, \n",
    "      \"AUSTRALIA\", \"+61 987 654 3210\", \"789 12 6118\"\n",
    "     )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e77079c5-4005-42d4-8f8b-df9d338cc83b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(employees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c069ead4-5b79-4162-846b-fc0be8120556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employeesDF = spark. \\\n",
    "    createDataFrame(employees,\n",
    "                    schema=\"\"\"employee_id INT, first_name STRING, \n",
    "                    last_name STRING, salary FLOAT, nationality STRING,\n",
    "                    phone_number STRING, ssn STRING\"\"\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b57b22d-80ad-4665-b587-8546ad641bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- salary: float (nullable = true)\n",
      " |-- nationality: string (nullable = true)\n",
      " |-- phone_number: string (nullable = true)\n",
      " |-- ssn: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9dbdcbe-bd32-4170-bc1c-93edf1603c26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|nationality   |phone_number    |ssn        |\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|1          |Scott     |Tiger    |1000.0|united states |+1 123 456 7890 |123 45 6789|\n",
      "|2          |Henry     |Ford     |1250.0|India         |+91 234 567 8901|456 78 9123|\n",
      "|3          |Nick      |Junior   |750.0 |united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|4          |Bill      |Gomes    |1500.0|AUSTRALIA     |+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c349666-800c-447f-a2d5-2fef5320c1d6",
   "metadata": {},
   "source": [
    "## Categories of Functions\n",
    "\n",
    "- ### String Manipulation Functions\n",
    "    - Case Conversion - lower, upper\n",
    "    - Getting Length - length\n",
    "    - Extracting substrings - substring, split\n",
    "    - Trimming - trim, ltrim, rtrim\n",
    "    - Padding - lpad, rpad\n",
    "    - Concatenating string - concat, concat_ws\n",
    "- ### Date Manipulation Functions\n",
    "    - Getting current date and time - current_date, current_timestamp\n",
    "    - Date Arithmetic - date_add, date_sub, datediff, months_between, add_months, next_day\n",
    "    - Beginning and Ending Date or Time - last_day, trunc, date_trunc\n",
    "    - Formatting Date - date_format\n",
    "    - Extracting Information - dayofyear, dayofmonth, dayofweek, year, month\n",
    "- ### Aggregate Functions\n",
    "    - count, countDistinct\n",
    "    - sum, avg\n",
    "    - min, max\n",
    "- ### Other Functions - We will explore depending on the use cases.\n",
    "    - CASE and WHEN\n",
    "    - CAST for type casting\n",
    "    - Functions to manage special types such as ARRAY, MAP, STRUCT type columns\n",
    "- ### Special Functions \n",
    "    - col \n",
    "    - lit\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e300981-eee8-42dd-bda5-3de1b865f7fe",
   "metadata": {},
   "source": [
    ">Special functions such as **col** and **lit**  are typically used to convert the strings to column type.\n",
    "\n",
    ">If there are no transformations on any column in any function then we should be able to pass all column names as strings.\n",
    "\n",
    ">If not we need to pass all columns as type column by using **col** function.\n",
    "\n",
    ">If we want to apply transformations using some of the functions then passing column names as strings will not suffice. We have to pass them as column type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bd288a7-42ba-44dc-a9f9-53f2c51d59c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|     Scott|    Tiger|\n",
      "|     Henry|     Ford|\n",
      "|      Nick|   Junior|\n",
      "|      Bill|    Gomes|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF. \\\n",
    "    select(\"first_name\", \"last_name\"). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1411917e-ff54-4725-9293-7d5b62cb82a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|   nationality|count|\n",
      "+--------------+-----+\n",
      "|united KINGDOM|    1|\n",
      "|     AUSTRALIA|    1|\n",
      "|         India|    1|\n",
      "| united states|    1|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF. \\\n",
    "    groupBy(\"nationality\"). \\\n",
    "    count(). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a74d37d7-a70d-4790-a0a0-da1a31572a1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n",
      "|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          4|      Bill|    Gomes|1500.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF. \\\n",
    "    orderBy(\"employee_id\"). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e0789f9-a197-4b33-be1a-68630f5445c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|     Scott|    Tiger|\n",
      "|     Henry|     Ford|\n",
      "|      Nick|   Junior|\n",
      "|      Bill|    Gomes|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF. \\\n",
    "    select(col(\"first_name\"), col(\"last_name\")). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40f65ba8-ed56-4f84-93ad-c4d4576abb15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|First_name|Last_Name|\n",
      "+----------+---------+\n",
      "|     SCOTT|    TIGER|\n",
      "|     HENRY|     FORD|\n",
      "|      NICK|   JUNIOR|\n",
      "|      BILL|    GOMES|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF. \\\n",
    "    select(upper(\"first_name\").alias(\"First_name\"), upper(\"last_Name\").alias(\"Last_Name\")). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed249de2-72ee-4645-91a6-f5ba48e2f7d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|      Names|\n",
      "+-----------+\n",
      "|SCOTT TIGER|\n",
      "| HENRY FORD|\n",
      "|NICK JUNIOR|\n",
      "| BILL GOMES|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF. \\\n",
    "    select(concat(upper(\"first_name\"),lit(\" \"), upper(\"last_Name\")).alias(\"Names\")). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cbac00b-6222-4e2a-b8d0-6a09bf790d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|upper(nationality)|count|\n",
      "+------------------+-----+\n",
      "|    UNITED KINGDOM|    1|\n",
      "|         AUSTRALIA|    1|\n",
      "|             INDIA|    1|\n",
      "|     UNITED STATES|    1|\n",
      "+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF. \\\n",
    "    groupBy(upper(\"nationality\")). \\\n",
    "    count(). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb842d57-2825-4d12-9bed-f699d5940e67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'desc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m employeesDF\u001b[38;5;241m.\u001b[39m \\\n\u001b[0;32m----> 2\u001b[0m     orderBy(\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memployee_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m())\u001b[38;5;241m.\u001b[39m \\\n\u001b[1;32m      3\u001b[0m     show()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'desc'"
     ]
    }
   ],
   "source": [
    "employeesDF. \\\n",
    "    orderBy(\"employee_id\".desc()). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aac56d9-298e-474e-b524-ad867fbf7a90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employeesDF. \\\n",
    "    orderBy(col(\"employee_id\").desc()). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d782036-aba2-4a1d-8a80-21b6a247f7ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employeesDF. \\\n",
    "    orderBy(col(\"first_name\").desc()). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99075ae-125d-46b8-bde9-9a0fc3df7b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Alternative - we can also refer column names using Data Frame like this\n",
    "employeesDF. \\\n",
    "    orderBy(upper(employeesDF['first_name']).alias('first_name')). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f72515-104e-4229-b8c5-4b3d2acf764a",
   "metadata": {},
   "source": [
    "### Common String Manipulation Functions\n",
    "- Case Conversion and Length\n",
    "    - Convert all the alphabetic characters in a string to uppercase - upper\n",
    "    - Convert all the alphabetic characters in a string to lowercase - lower\n",
    "    - Convert first character in a string to uppercase - initcap\n",
    "    - Get number of characters in a string - length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5548f77c-dd25-492c-88e6-1b2d114f0ed5",
   "metadata": {},
   "source": [
    "Concatenating Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8d1740-1414-47f8-8f4f-7206d04c3948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employeesDF. \\\n",
    "    withColumn(\"full_name\", concat(\"first_name\",lit(\", \"), \"last_name\")). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5151bd31-a014-4c00-9d58-95e6cc01f9e4",
   "metadata": {},
   "source": [
    "Case Conversion and length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89271943-ef0d-44e7-af96-924afea36e7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employeesDF. \\\n",
    "  select(\"employee_id\", \"nationality\"). \\\n",
    "  withColumn(\"nationality_upper\", upper(col(\"nationality\"))). \\\n",
    "  withColumn(\"nationality_lower\", lower(col(\"nationality\"))). \\\n",
    "  withColumn(\"nationality_initcap\", initcap(col(\"nationality\"))). \\\n",
    "  withColumn(\"nationality_length\", length(col(\"nationality\"))). \\\n",
    "  show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835b073a-e22c-4162-9d1f-16fd9ccf8b66",
   "metadata": {},
   "source": [
    "### Extracting Strings using substring\n",
    "- If we are processing ***fixed length*** columns then we use substring to extract the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f88df5-b851-43da-b8d4-b170f14bfcbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = \"Hello World\"\n",
    "s.index('H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee6b21-32ce-4600-8c23-9550cef69f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employeesDF. \\\n",
    "    select(\"employee_id\", \"phone_number\", \"ssn\"). \\\n",
    "    withColumn(\"phone_last4\", substring(col(\"phone_number\"), -4, 4).cast(\"int\")). \\\n",
    "    withColumn(\"ssn_last4\", substring(col(\"ssn\"), 8, 4).cast(\"int\")). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d08bd5-383f-429f-8b6b-3e4edaf6202c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employeesDF. \\\n",
    "    select(\"employee_id\", \"phone_number\", \"ssn\"). \\\n",
    "    withColumn(\"phone_last4\", substring(col(\"phone_number\"), -4, 4).cast(\"int\")). \\\n",
    "    withColumn(\"ssn_last4\", substring(col(\"ssn\"), 8, 4).cast(\"int\")). \\\n",
    "    printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38564fb-af61-47eb-8fb4-7816b5001dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "help(employeesDF.employee_id.substr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ed3748-6c9d-4560-9a49-5417592be068",
   "metadata": {},
   "source": [
    "### Extracting Strings using split\n",
    "- If we are processing variable length columns with delimiter then we use split to extract the information.\n",
    "- processing variable length columns with delimiter then we use split to extract the information.\n",
    "- **split** takes 2 arguments, **column** and **delimiter**.\n",
    "- **split** convert each string into array and we can access the elements using **index**.\n",
    "- We can also use **explode** in conjunction with split to explode the list or array into records in Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa30348c-5937-4430-a4d0-004cb51e5685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employees = [(1, \"Scott\", \"Tiger\", 1000.0, \n",
    "                      \"united states\", \"+1 123 456 7890,+1 234 567 8901\", \"123 45 6789\"\n",
    "                     ),\n",
    "                     (2, \"Henry\", \"Ford\", 1250.0, \n",
    "                      \"India\", \"+91 234 567 8901\", \"456 78 9123\"\n",
    "                     ),\n",
    "                     (3, \"Nick\", \"Junior\", 750.0, \n",
    "                      \"united KINGDOM\", \"+44 111 111 1111,+44 222 222 2222\", \"222 33 4444\"\n",
    "                     ),\n",
    "                     (4, \"Bill\", \"Gomes\", 1500.0, \n",
    "                      \"AUSTRALIA\", \"+61 987 654 3210,+61 876 543 2109\", \"789 12 6118\"\n",
    "                     )\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84abcbce-ed53-48da-93bc-a5350acb36dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employeesDF = spark. \\\n",
    "    createDataFrame(employees,\n",
    "                    schema=\"\"\"employee_id INT, first_name STRING, \n",
    "                    last_name STRING, salary FLOAT, nationality STRING,\n",
    "                    phone_numbers STRING, ssn STRING\"\"\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4153393b-e4a5-4f6f-b032-3252bf0da110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employeesDF. \\\n",
    "    select('employee_id', 'phone_numbers'). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f459f4-23d1-45ee-b8ca-3106c9643fab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employeesDF = employeesDF. \\\n",
    "    select('employee_id', 'phone_numbers', 'ssn'). \\\n",
    "    withColumn('phone_number', explode(split('phone_numbers', ',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46a2a33-ee2e-45cd-9bc8-eb3496f08850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employeesDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b1ccf2-edea-48ac-aacd-d73a0ce6b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "employeesDF. \\\n",
    "    groupBy('employee_id'). \\\n",
    "    count(). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8fac3a-fa91-4967-9d0e-3f9e3443f1ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Padding Characters around Strings\n",
    "- We use lpad to pad a string with a specific character on leading or left side and rpad to pad on trailing or right side.\n",
    "- Both lpad and rpad, take 3 arguments - column or expression, desired length and the character need to be padded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fb621c-32e8-47eb-b575-39a2d692990e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employees = [(1, \"Scott\", \"Tiger\", 1000.0, \n",
    "                      \"united states\", \"+1 123 456 7890\", \"123 45 6789\"\n",
    "                     ),\n",
    "                     (2, \"Henry\", \"Ford\", 1250.0, \n",
    "                      \"India\", \"+91 234 567 8901\", \"456 78 9123\"\n",
    "                     ),\n",
    "                     (3, \"Nick\", \"Junior\", 750.0, \n",
    "                      \"united KINGDOM\", \"+44 111 111 1111\", \"222 33 4444\"\n",
    "                     ),\n",
    "                     (4, \"Bill\", \"Gomes\", 1500.0, \n",
    "                      \"AUSTRALIA\", \"+61 987 654 3210\", \"789 12 6118\"\n",
    "                     )\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d66535-d1c9-4e32-984b-d4daf2cd2c36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employeesDF = spark.createDataFrame(employees). \\\n",
    "    toDF(\"employee_id\", \"first_name\",\n",
    "         \"last_name\", \"salary\",\n",
    "         \"nationality\", \"phone_number\",\n",
    "         \"ssn\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc149ae7-85a9-413a-81f8-e57ca8683194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employeesDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2598b312-5b6c-427d-b6c3-fabc42a278e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employeesDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b3aa9-20f4-4d1e-8ea3-cc31556514ad",
   "metadata": {},
   "source": [
    "Length of the employee_id should be 5 characters and should be padded with zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09969000-30f7-4fc8-aa75-676720c3d7a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "empFixedDF = employeesDF.select(\n",
    "    concat(\n",
    "        lpad(\"employee_id\", 5, \"0\")\n",
    "    ).alias(\"employee\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1993cd3a-fbe4-4d49-b2bf-95e8e4fbb11b",
   "metadata": {},
   "source": [
    "Length of first_name and last_name should be 10 characters and should be padded with - on the right side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c52ea9-af79-46c2-b7bb-a032a7caecef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "empFixedDF = employeesDF.select(\n",
    "    concat(\n",
    "        \n",
    "        rpad(\"first_name\", 10, \"-\"), \n",
    "        rpad(\"last_name\", 10, \"-\")\n",
    "    ).alias(\"employee\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855c2b52-e305-4796-a9c9-534edeb0c541",
   "metadata": {},
   "source": [
    "Length of salary should be 10 characters and should be padded with zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3c13b9-ac73-42c6-8c94-58b21c0db548",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "empFixedDF = employeesDF.select(\n",
    "    concat(\n",
    "                lpad(\"salary\", 10, \"0\")\n",
    "    ).alias(\"employee\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df0c11a-12b6-4592-88e0-8fc79416ad96",
   "metadata": {},
   "source": [
    "Length of the nationality should be 15 characters and should be padded with - on the right side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9177f804-3684-4d60-8300-aff835a29270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "empFixedDF = employeesDF.select(\n",
    "    concat(\n",
    "         \n",
    "        rpad(\"nationality\", 15, \"-\"), \n",
    "       \n",
    "    ).alias(\"employee\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32479a47-f647-4078-86b5-e12032021a5b",
   "metadata": {},
   "source": [
    "Length of the phone_number should be 17 characters and should be padded with - on the right side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73d4bf4-d087-4d56-ab23-f2a6926d0d1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "empFixedDF = employeesDF.select(\n",
    "    concat(\n",
    "        rpad(\"phone_number\", 17, \"-\")\n",
    "    ).alias(\"employee\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa359e0a-ed22-4e58-a9b3-eefbaaa84d39",
   "metadata": {},
   "source": [
    "Length of the ssn can be left as is. It is 11 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3220c-fad1-4049-ac57-d378617386b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "empFixedDF = employeesDF.select(\n",
    "    concat(\n",
    "       rpad(\"phone_number\", 17, \"-\"), \n",
    "        \"ssn\"\n",
    "    ).alias(\"employee\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d02d38-078a-4f87-a206-c40c1c5d474d",
   "metadata": {},
   "source": [
    "### Trimming Characters from Strings\n",
    "- We typically use trimming to remove unnecessary characters from fixed length records.\n",
    "- As of now Spark trim functions take the column as argument and remove leading or trailing spaces. However, we can use **expr** or **selectExpr** to use Spark SQL based trim functions to remove leading or trailing spaces or any other such characters.\n",
    "    - Trim spaces towards left - **ltrim**\n",
    "    - Trim spaces towards right - **rtrim**\n",
    "    - Trim spaces on both sides - **trim**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b519033-2377-4fc9-aa58-00dcecae6bd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = [(\"   Hello.    \",) ]\n",
    "df = spark.createDataFrame(l).toDF(\"dummy\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ae4fcd-33f6-47e0-ab7a-4fa7afa6647e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql('DESCRIBE FUNCTION rtrim').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8422ae-2e1c-42d2-9f07-5a2163745e62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if we do not specify trimStr, it will be defaulted to space\n",
    "df.withColumn(\"ltrim\", expr(\"ltrim(dummy)\")). \\\n",
    "  withColumn(\"rtrim\", expr(\"rtrim('.', rtrim(dummy))\")). \\\n",
    "  withColumn(\"trim\", trim(col(\"dummy\"))). \\\n",
    "  show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa849d27-d367-4ef3-97c3-540447f61d7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql('DESCRIBE FUNCTION trim').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9548b43-5b87-4449-8711-7d4b7c720200",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.withColumn(\"ltrim\", expr(\"trim(LEADING ' ' FROM dummy)\")). \\\n",
    "  withColumn(\"rtrim\", expr(\"trim(TRAILING '.' FROM rtrim(dummy))\")). \\\n",
    "  withColumn(\"trim\", expr(\"trim(BOTH ' ' FROM dummy)\")). \\\n",
    "  show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce090ca-73f6-4da3-883c-b200ee3fc7a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Date and Time Manipulation Functions\n",
    "- We can use ***current_date*** to get todayâ€™s server date.\n",
    "     - Date will be returned using ***yyyy-MM-dd*** format.\n",
    "- We can use ***current_timestamp*** to get current server time.\n",
    "    - Timestamp will be returned using ***yyyy-MM-dd HH:mm:ss:SSS*** format.\n",
    "    - Hours will be by default in 24 hour format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a188857-45bb-4b2e-ab76-7cd9133d6043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.select(current_date()).show() #yyyy-MM-dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cfcb09-05e8-4b4a-8cb2-12aab88f4886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.select(current_timestamp()).show(truncate=False) #yyyy-MM-dd HH:mm:ss.SSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4c89c0-5b45-4361-a20d-56c17d80447c",
   "metadata": {
    "tags": []
   },
   "source": [
    "converting a string which contain date or timestamp in non-standard format to standard date or time using to_date or to_timestamp function respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22159837-dc45-483d-aa02-0956b42bac5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.select(to_date(lit('20210228'), 'yyyyMMdd').alias('to_date')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c48511-fdd8-4229-924e-01a7d5bcb8d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.select(to_timestamp(lit('20210228 1725'), 'yyyyMMdd HHmm').alias('to_timestamp')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c842c1d-a042-4680-84d5-11219fd41479",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Date and Time Arithmetic\n",
    "- Adding days to a date or timestamp - **date_add**\n",
    "- Subtracting days from a date or timestamp - **date_sub**\n",
    "- Getting difference between 2 dates or timestamps - **datediff**\n",
    "- Getting the number of months between 2 dates or timestamps - **months_between**\n",
    "- Adding months to a date or timestamp - **add_months**\n",
    "- Getting next day from a given date - **next_day**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23fe917-f497-4fb9-942a-1ab3a90cca6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimes = [(\"2014-02-28\", \"2014-02-28 10:00:00.123\"),\n",
    "                     (\"2016-02-29\", \"2016-02-29 08:08:08.999\"),\n",
    "                     (\"2017-10-31\", \"2017-12-31 11:59:59.123\"),\n",
    "                     (\"2019-11-30\", \"2019-08-31 00:00:00.000\")\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006be922-032d-4fe8-ba8a-b620f6c632ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF = spark.createDataFrame(datetimes, schema=\"date STRING, time STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec20a0-9628-44e0-b676-e606e3131c9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba392ca-7fbc-4d74-bd52-f41ed364e57b",
   "metadata": {},
   "source": [
    "- Add 10 days to both date and time values.\n",
    "- Subtract 10 days from both date and time values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639a682-91e9-4f68-b3d1-2e7cac49ff7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF. \\\n",
    "    withColumn(\"date_add_date\", date_add(\"date\", 10)). \\\n",
    "    withColumn(\"date_add_time\", date_add(\"time\", 10)). \\\n",
    "    withColumn(\"date_sub_date\", date_sub(\"date\", 10)). \\\n",
    "    withColumn(\"date_sub_time\", date_sub(\"time\", 10)). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e182fd-fb05-4a8a-af64-ddcde60a68d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF. \\\n",
    "    withColumn(\"months_between_date\", round(months_between(current_date(), \"date\"), 2)). \\\n",
    "    withColumn(\"months_between_time\", round(months_between(current_timestamp(), \"time\"), 2)). \\\n",
    "    withColumn(\"add_months_date\", add_months(\"date\", 3)). \\\n",
    "    withColumn(\"add_months_time\", add_months(\"time\", 3)). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7288ab-4379-4100-8024-3846c59ddf32",
   "metadata": {},
   "source": [
    "Getting the difference between current_date and date values as well as current_timestamp and time values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937d43d5-d0cd-4bfd-a3d4-dd3c8b38c732",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF. \\\n",
    "    withColumn(\"datediff_date\", datediff(current_date(), \"date\")). \\\n",
    "    withColumn(\"datediff_time\", datediff(current_timestamp(), \"time\")). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70379b04-975f-4022-843e-023adbcd1a8a",
   "metadata": {},
   "source": [
    "- Getting the number of months between current_date and date values as well as current_timestamp and time values.\n",
    "- Adding 3 months to both date values as well as time values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5b292c-0bb8-421d-8b49-d6419cc21c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF. \\\n",
    "    withColumn(\"months_between_date\", round(months_between(current_date(), \"date\"), 2)). \\\n",
    "    withColumn(\"months_between_time\", round(months_between(current_timestamp(), \"time\"), 2)). \\\n",
    "    withColumn(\"add_months_date\", add_months(\"date\", 3)). \\\n",
    "    withColumn(\"add_months_time\", add_months(\"time\", 3)). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8155b9-0bab-4b14-9bb6-feff1656edda",
   "metadata": {},
   "source": [
    "### Using Date and Time Trunc Functions\n",
    "- We can use **trunc** or **date_trunc** for the same to get the beginning date of the **week, month, current year etc** by passing ***date*** or ***timestamp*** to it.\n",
    "- We can use **trunc** to get beginning **date of the month or year** by passing ***date or timestamp*** to it - for example trunc(current_date(), \"MM\") will give the first of the current month.\n",
    "- We can use **date_trunc** to get beginning date of the month or year as well as beginning time of the day or hour by passing timestamp to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c091338-06e6-4539-a25e-9b3626da9d74",
   "metadata": {},
   "source": [
    "Creating a Dataframe by name datetimesDF with columns date and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef229eb9-1df0-41d3-9874-ab75465dc938",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes = [(\"2014-02-28\", \"2014-02-28 10:00:00.123\"),\n",
    "                     (\"2016-02-29\", \"2016-02-29 08:08:08.999\"),\n",
    "                     (\"2017-10-31\", \"2017-12-31 11:59:59.123\"),\n",
    "                     (\"2019-11-30\", \"2019-08-31 00:00:00.000\")\n",
    "                ]\n",
    "datetimesDF = spark.createDataFrame(datetimes, schema=\"date STRING, time STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e149d6-49ac-4ddc-ae86-149789ac6587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78411e28-d15f-4abd-8d67-6066c34bf516",
   "metadata": {},
   "source": [
    "Getting **beginning month** and **year** date using date field and beginning year date using time field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe35b1-de39-4009-a0f0-5e2389e5b5ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF. \\\n",
    "    withColumn(\"date_trunc\", trunc(\"date\", \"MM\")). \\\n",
    "    withColumn(\"time_trunc\", trunc(\"time\", \"yy\")). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd83d8-e576-454f-b41e-280dafd30e21",
   "metadata": {
    "tags": []
   },
   "source": [
    "Gettting **beginning hour** time using date and time field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babb6cc5-e42d-4019-bc62-68f2c33a55fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF. \\\n",
    "    withColumn(\"date_trunc\", date_trunc('MM', \"date\")). \\\n",
    "    withColumn(\"time_trunc\", date_trunc('yy', \"time\")). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f5796-acd4-4431-9280-82b54c00d910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF. \\\n",
    "    withColumn(\"date_dt\", date_trunc(\"HOUR\", \"date\")). \\\n",
    "    withColumn(\"time_dt\", date_trunc(\"HOUR\", \"time\")). \\\n",
    "    withColumn(\"time_dt1\", date_trunc(\"dd\", \"time\")). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0620e3f6-15df-4e68-9efc-97c20e10f841",
   "metadata": {},
   "source": [
    "### Date and Time Extract Functions\n",
    "- year\n",
    "- month\n",
    "- weekofyear\n",
    "- dayofyear\n",
    "- dayofmonth\n",
    "- dayofweek\n",
    "- hour\n",
    "-  minute\n",
    "- second\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50911b6f-aed3-462a-9511-65a3bbad018a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = [(\"X\", )]\n",
    "df = spark.createDataFrame(l).toDF(\"dummy\")\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8a4fa2-9ab7-4139-aaf6-918cabd06006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.select(\n",
    "    current_date().alias('current_date'), \n",
    "    year(current_date()).alias('year'),\n",
    "    month(current_date()).alias('month'),\n",
    "    weekofyear(current_date()).alias('weekofyear'),\n",
    "    dayofyear(current_date()).alias('dayofyear'),\n",
    "    dayofmonth(current_date()).alias('dayofmonth'),\n",
    "    dayofweek(current_date()).alias('dayofweek')\n",
    ").show() #yyyy-MM-dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad5476a-1933-444c-b804-3bde1a1cac43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from pyspark.sql import functions\n",
    "#help(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8379b8-1514-401c-8a09-cfe41ec1eefa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.select(\n",
    "    current_timestamp().alias('current_timestamp'), \n",
    "    year(current_timestamp()).alias('year'),\n",
    "    month(current_timestamp()).alias('month'),\n",
    "    dayofmonth(current_timestamp()).alias('dayofmonth'),\n",
    "    hour(current_timestamp()).alias('hour'),\n",
    "    minute(current_timestamp()).alias('minute'),\n",
    "    second(current_timestamp()).alias('second')\n",
    ").show(truncate=False) #yyyy-MM-dd HH:mm:ss.SSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b613e9e5-31bd-4204-aa10-5c49f99316a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using to_date and to_timestamp\n",
    "- **yyyy-MM-dd** is the standard date format\n",
    "- **yyyy-MM-dd HH:mm:ss.SSS** is the standard timestamp format\n",
    "- If data is not in the expected standard format, we can use **to_date** and **to_timestamp** to convert non standard dates and timestamps to standard ones respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac79dca-64b4-4005-9ded-e5d24205f942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimes = [(20140228, \"28-Feb-2014 10:00:00.123\"),\n",
    "                     (20160229, \"20-Feb-2016 08:08:08.999\"),\n",
    "                     (20171031, \"31-Dec-2017 11:59:59.123\"),\n",
    "                     (20191130, \"31-Aug-2019 00:00:00.000\")\n",
    "                ]\n",
    "\n",
    "datetimesDF = spark.createDataFrame(datetimes, schema=\"date BIGINT, time STRING\")\n",
    "\n",
    "datetimesDF.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff43872d-b711-4bb1-91c5-4b87e2f1e07a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = [(\"X\", )]\n",
    "df = spark.createDataFrame(l).toDF(\"dummy\")\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2710ece-6e72-45d5-8e53-badc95a95a76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.select(to_date(lit('20210302'), 'yyyyMMdd').alias('to_date')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb242fbc-0759-461e-8719-02c09ff08dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# year and day of year to standard date\n",
    "df.select(to_date(lit('2021061'), 'yyyyDDD').alias('to_date')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780a026d-5382-41fe-8495-bb79e07c94a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.select(to_date(lit('02/03/2021'), 'dd/M/yyyy').alias('to_date')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7bc94e-4f57-46dd-821b-d88d1b188edf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.select(to_date(lit('02-03-2021'), 'dd-MM-yyyy').alias('to_date')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008d3e39-6db0-4ad1-864d-6bea1657d57d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.select(to_date(lit('02-Mar-2021'), 'dd-MMM-yyyy').alias('to_date')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b0a520-1c61-4c48-8b30-f509d00a1804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.select(to_date(lit('02-March-2021'), 'dd-MMMM-yyyy').alias('to_date')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd18f672-8c73-4f48-87ac-bb0d4fceaf7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.select(to_date(lit('March 2, 2021'), 'MMMM d, yyyy').alias('to_date')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b1363f-5041-42ce-bfc9-adf18b85fe09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.select(to_timestamp(lit('02-Mar-2021'), 'dd-MMM-yyyy').alias('to_date')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314e929b-c3c6-48a4-88d1-a3a61773f877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93003ec2-fc02-4626-a300-b47e4520a12d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64afe42a-1aa3-493e-a42c-6c4055a9ae72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF. \\\n",
    "    withColumn('to_date', to_date(col('date').cast('string'), 'yyyyMMdd')). \\\n",
    "    withColumn('to_timestamp', to_timestamp(col('time'), 'dd-MMM-yyyy HH:mm:ss.SSS')). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52db6789-0ad6-4aac-bd69-725df1a4527e",
   "metadata": {},
   "source": [
    "### Using date_format Function\n",
    "- use date_format to extract the required information in a desired format from standard date or timestamp. \n",
    "    - yyyy\n",
    "    - MM\n",
    "    - dd\n",
    "    - DD\n",
    "    - HH\n",
    "    - hh\n",
    "    - mm\n",
    "    - ss\n",
    "    - SSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb073a22-9d37-4514-88e0-fd9c38392a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimes = [(\"2014-02-28\", \"2014-02-28 10:00:00.123\"),\n",
    "                     (\"2016-02-29\", \"2016-02-29 08:08:08.999\"),\n",
    "                     (\"2017-10-31\", \"2017-12-31 11:59:59.123\"),\n",
    "                     (\"2019-11-30\", \"2019-08-31 00:00:00.000\")\n",
    "                ]\n",
    "datetimesDF = spark.createDataFrame(datetimes, schema=\"date STRING, time STRING\")\n",
    "\n",
    "datetimesDF.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6788a8b-8c76-42a7-897f-b19444fc70d2",
   "metadata": {},
   "source": [
    "Get the year and month from both date and time columns using _yyyyMM format_. Also make sure that the data type is converted to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24ff398-62a5-4d77-ac4f-5c45b21186f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF. \\\n",
    "    withColumn(\"date_ym\", date_format(\"date\", \"yyyyMM\")). \\\n",
    "    withColumn(\"time_ym\", date_format(\"time\", \"yyyyMM\")). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4b794-d7ed-4738-9257-e172d5d9e9bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF. \\\n",
    "    withColumn(\"date_ym\", date_format(\"date\", \"yyyyMM\")). \\\n",
    "    withColumn(\"time_ym\", date_format(\"time\", \"yyyyMM\")). \\\n",
    "    printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7243fbd-e236-4f79-8f4d-442afb76b3e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF. \\\n",
    "    withColumn(\"date_ym\", date_format(\"date\", \"yyyyMM\").cast('int')). \\\n",
    "    withColumn(\"time_ym\", date_format(\"time\", \"yyyyMM\").cast('int')). \\\n",
    "    printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d0173d-1e48-4f1d-b2dd-9416f695dbce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF. \\\n",
    "    withColumn(\"date_ym\", date_format(\"date\", \"yyyyMM\").cast('int')). \\\n",
    "    withColumn(\"time_ym\", date_format(\"time\", \"yyyyMM\").cast('int')). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e567e91-d24c-46da-bc24-2046180bf724",
   "metadata": {
    "tags": []
   },
   "source": [
    "yyyyMMddHHmmss format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f980e94e-74a0-4e6a-8618-85039b2e8442",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF. \\\n",
    "    withColumn(\"date_dt\", date_format(\"date\", \"yyyyMMddHHmmss\")). \\\n",
    "    withColumn(\"date_ts\", date_format(\"time\", \"yyyyMMddHHmmss\")). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81e5f0-1b23-4638-a7b7-238c85e1a15f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF. \\\n",
    "    withColumn(\"date_dt\", date_format(\"date\", \"yyyyMMddHHmmss\").cast('long')). \\\n",
    "    withColumn(\"date_ts\", date_format(\"time\", \"yyyyMMddHHmmss\").cast('long')). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105cacc1-90d3-4ae1-8b47-4a2356350503",
   "metadata": {},
   "source": [
    "Getting year and day of year using yyyyDDD format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94982461-67c6-4278-873b-ae2c5f2b4cda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF. \\\n",
    "    withColumn(\"date_yd\", date_format(\"date\", \"yyyyDDD\").cast('int')). \\\n",
    "    withColumn(\"time_yd\", date_format(\"time\", \"yyyyDDD\").cast('int')). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e695e42-d4de-418e-89d2-4b3b1e045037",
   "metadata": {},
   "source": [
    "Getting complete description of the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fbbde4-bb8b-4a64-bfe6-709e16a36569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF. \\\n",
    "    withColumn(\"date_desc\", date_format(\"date\", \"MMMM d, yyyy\")). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106fe834-56a2-494e-a1bd-c523a55055a9",
   "metadata": {},
   "source": [
    "Getting name of the week day using date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05405de-040f-4b80-a0db-7415ec19bd43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF. \\\n",
    "    withColumn(\"day_name_abbr\", date_format(\"date\", \"EE\")). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f095f443-0e2c-45ac-abb1-7df26754f8e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetimesDF. \\\n",
    "    withColumn(\"day_name_full\", date_format(\"date\", \"EEEE\")). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f749374-096a-4304-9ebe-a3268c55b4b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dealing with Unix Timestamp\n",
    "- It is an integer and started from January 1st 1970 Midnight UTC.\n",
    "- Beginning time is also known as epoch and is incremented by 1 every second.\n",
    "- We can convert Unix Timestamp to regular date or timestamp and vice versa.\n",
    "- We can use **unix_timestamp** to convert regular date or timestamp to a unix timestamp value. For example unix_timestamp(lit(\"2019-11-19 00:00:00\"))\n",
    "- We can use from_unixtime to convert unix timestamp to regular date or timestamp. For example from_unixtime(lit(1574101800))\n",
    "- We can also pass format to both the functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de29d388-2b7c-4e79-8696-0876d25acd0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------------+\n",
      "|dateid  |date      |time                   |\n",
      "+--------+----------+-----------------------+\n",
      "|20140228|2014-02-28|2014-02-28 10:00:00.123|\n",
      "|20160229|2016-02-29|2016-02-29 08:08:08.999|\n",
      "|20171031|2017-10-31|2017-12-31 11:59:59.123|\n",
      "|20191130|2019-11-30|2019-08-31 00:00:00.000|\n",
      "+--------+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimes = [(20140228, \"2014-02-28\", \"2014-02-28 10:00:00.123\"),\n",
    "                     (20160229, \"2016-02-29\", \"2016-02-29 08:08:08.999\"),\n",
    "                     (20171031, \"2017-10-31\", \"2017-12-31 11:59:59.123\"),\n",
    "                     (20191130, \"2019-11-30\", \"2019-08-31 00:00:00.000\")\n",
    "                ]\n",
    "datetimesDF = spark.createDataFrame(datetimes).toDF(\"dateid\", \"date\", \"time\")\n",
    "\n",
    "datetimesDF.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7e83f37-651d-47a0-b91e-ca539c7181cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+------------+----------+----------+\n",
      "|  dateid|      date|                time|unix_date_id| unix_date| unix_time|\n",
      "+--------+----------+--------------------+------------+----------+----------+\n",
      "|20140228|2014-02-28|2014-02-28 10:00:...|  1393545600|1393545600|1393581600|\n",
      "|20160229|2016-02-29|2016-02-29 08:08:...|  1456704000|1456704000|1456733288|\n",
      "|20171031|2017-10-31|2017-12-31 11:59:...|  1509408000|1509408000|1514721599|\n",
      "|20191130|2019-11-30|2019-08-31 00:00:...|  1575072000|1575072000|1567209600|\n",
      "+--------+----------+--------------------+------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "datetimesDF. \\\n",
    "    withColumn(\"unix_date_id\", unix_timestamp(col(\"dateid\").cast(\"string\"), \"yyyyMMdd\")). \\\n",
    "    withColumn(\"unix_date\", unix_timestamp(\"date\", \"yyyy-MM-dd\")). \\\n",
    "    withColumn(\"unix_time\", unix_timestamp(\"time\")). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f722a40-c5bb-4b51-bffd-1a9ff7f4d4a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  unixtime|\n",
      "+----------+\n",
      "|1393561800|\n",
      "|1456713488|\n",
      "|1514701799|\n",
      "|1567189800|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unixtimes = [(1393561800, ),\n",
    "             (1456713488, ),\n",
    "             (1514701799, ),\n",
    "             (1567189800, )\n",
    "            ]\n",
    "unixtimesDF = spark.createDataFrame(unixtimes).toDF(\"unixtime\")\n",
    "unixtimesDF.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6df0fe73-e0ba-4c40-aa13-52871d146211",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- unixtime: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unixtimesDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "331c3de9-edbf-43b5-83c4-a1dc856728d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------------------+\n",
      "|  unixtime|    date|               time|\n",
      "+----------+--------+-------------------+\n",
      "|1393561800|20140228|2014-02-28 04:30:00|\n",
      "|1456713488|20160229|2016-02-29 02:38:08|\n",
      "|1514701799|20171231|2017-12-31 06:29:59|\n",
      "|1567189800|20190830|2019-08-30 18:30:00|\n",
      "+----------+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unixtimesDF. \\\n",
    "    withColumn(\"date\", from_unixtime(\"unixtime\", \"yyyyMMdd\")). \\\n",
    "    withColumn(\"time\", from_unixtime(\"unixtime\")). \\\n",
    "    show()\n",
    "#yyyyMMdd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cbb78d-af48-4e70-a533-a9ba05150cc7",
   "metadata": {},
   "source": [
    "### Dealing with Nulls\n",
    "- We can use coalesce to return first non null value.\n",
    "- We also have traditional SQL style functions such as nvl. However, they can be used either with expr or selectExpr.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18c06ca2-9f34-451c-a6c7-60d69484d347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employees = [(1, \"Scott\", \"Tiger\", 1000.0, 10,\n",
    "                      \"united states\", \"+1 123 456 7890\", \"123 45 6789\"\n",
    "                     ),\n",
    "                     (2, \"Henry\", \"Ford\", 1250.0, None,\n",
    "                      \"India\", \"+91 234 567 8901\", \"456 78 9123\"\n",
    "                     ),\n",
    "                     (3, \"Nick\", \"Junior\", 750.0, '',\n",
    "                      \"united KINGDOM\", \"+44 111 111 1111\", \"222 33 4444\"\n",
    "                     ),\n",
    "                     (4, \"Bill\", \"Gomes\", 1500.0, 10,\n",
    "                      \"AUSTRALIA\", \"+61 987 654 3210\", \"789 12 6118\"\n",
    "                     )\n",
    "                ]\n",
    "employeesDF = spark.createDataFrame(employees,\n",
    "                    schema=\"\"\"employee_id INT, first_name STRING, last_name STRING, salary FLOAT,\n",
    "                    bonus STRING, nationality STRING,phone_number STRING, ssn STRING\"\"\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a6db164-6dc3-495d-84d5-a304ad32f175",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n",
      "|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          4|      Bill|    Gomes|1500.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1030a6e5-7de4-485e-83d4-926ee803de31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n",
      "|          2|     Henry|     Ford|1250.0|    0|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          4|      Bill|    Gomes|1500.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF. \\\n",
    "    withColumn('bonus', coalesce('bonus', lit(0))). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e3f6f37-cea3-42f1-9459-8be595964ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|bonus1|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|    10|\n",
      "|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123|  null|\n",
      "|          3|      Nick|   Junior| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|  null|\n",
      "|          4|      Bill|    Gomes|1500.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|    10|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF. \\\n",
    "    withColumn('bonus1', col('bonus').cast('int')). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "defdf4a7-6b92-4ab3-807d-b5680e03dd5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|bonus1|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|    10|\n",
      "|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123|     0|\n",
      "|          3|      Nick|   Junior| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|     0|\n",
      "|          4|      Bill|    Gomes|1500.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|    10|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF. \\\n",
    "    withColumn('bonus1', coalesce(col('bonus').cast('int'), lit(0))). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34b4d3ab-af3a-4e00-b0c3-c030a2cadd85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n",
      "|          2|     Henry|     Ford|1250.0|    0|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          4|      Bill|    Gomes|1500.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF. \\\n",
    "    withColumn('bonus', expr(\"nvl(bonus, 0)\")). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3914a085-8091-40d5-8536-ff4e2dece849",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n",
      "|          2|     Henry|     Ford|1250.0|    0|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|    0|united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          4|      Bill|    Gomes|1500.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF. \\\n",
    "    withColumn('bonus', expr(\"nvl(nullif(bonus, ''), 0)\")). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8d01379-88ac-49bd-83c1-09fc2f41f32b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+-------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|payment|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+-------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789| 1100.0|\n",
      "|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123| 1250.0|\n",
      "|          3|      Nick|   Junior| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|  750.0|\n",
      "|          4|      Bill|    Gomes|1500.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118| 1650.0|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF. \\\n",
    "    withColumn('payment', col('salary') + (col('salary') * coalesce(col('bonus').cast('int'), lit(0)) / 100)). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079576da-c0bf-4993-b4b8-9c11ed45a13e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using CASE and WHEN\n",
    "- **CASE** and **WHEN** is typically used to apply transformations based up on conditions. We can use CASE and WHEN similar to SQL using expr or selectExpr.\n",
    "- If we want to use APIs, Spark provides functions such as **when** and **otherwise**. when is available as part of pyspark.sql.functions. On top of column type that is generated using when we should be able to invoke otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "37e07e51-b1c2-4e41-8bab-be095829430b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n",
      "|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          4|      Bill|    Gomes|1500.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees = [(1, \"Scott\", \"Tiger\", 1000.0, 10,\n",
    "                      \"united states\", \"+1 123 456 7890\", \"123 45 6789\"\n",
    "                     ),\n",
    "                     (2, \"Henry\", \"Ford\", 1250.0, None,\n",
    "                      \"India\", \"+91 234 567 8901\", \"456 78 9123\"\n",
    "                     ),\n",
    "                     (3, \"Nick\", \"Junior\", 750.0, '',\n",
    "                      \"united KINGDOM\", \"+44 111 111 1111\", \"222 33 4444\"\n",
    "                     ),\n",
    "                     (4, \"Bill\", \"Gomes\", 1500.0, 10,\n",
    "                      \"AUSTRALIA\", \"+61 987 654 3210\", \"789 12 6118\"\n",
    "                     )\n",
    "                ]\n",
    "employeesDF = spark.createDataFrame(employees,\n",
    "                    schema=\"\"\"employee_id INT, first_name STRING, last_name STRING, salary FLOAT, \n",
    "                    bonus STRING, nationality STRING,phone_number STRING, ssn STRING\"\"\"\n",
    "                   )\n",
    "employeesDF.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e280f55e-d500-41aa-b65a-adb9ffd27655",
   "metadata": {},
   "source": [
    "transforming bonus to 0 in case of null or empty, otherwise return the bonus amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6a1b86c-5855-4bb3-aa5f-b977a9af35e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|bonus1|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|    10|\n",
      "|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123|     0|\n",
      "|          3|      Nick|   Junior| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|     0|\n",
      "|          4|      Bill|    Gomes|1500.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|    10|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF. \\\n",
    "    withColumn('bonus1', coalesce(col('bonus').cast('int'), lit(0))). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8ea18f8-c6d7-49d4-946f-df57ba23c68d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n",
      "|          2|     Henry|     Ford|1250.0|    0|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|    0|united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          4|      Bill|    Gomes|1500.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF. \\\n",
    "    withColumn('bonus', \n",
    "        expr(\"\"\"\n",
    "            CASE WHEN bonus IS NULL OR bonus = '' THEN 0\n",
    "            ELSE bonus\n",
    "            END\n",
    "            \"\"\")\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4511fcd2-d820-41c0-b7f9-8dafcabfedec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mwhen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColumn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Evaluates a list of conditions and returns one of multiple possible result expressions.\n",
       "If :func:`pyspark.sql.Column.otherwise` is not invoked, None is returned for unmatched\n",
       "conditions.\n",
       "\n",
       ".. versionadded:: 1.4.0\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "condition : :class:`~pyspark.sql.Column`\n",
       "    a boolean :class:`~pyspark.sql.Column` expression.\n",
       "value :\n",
       "    a literal value, or a :class:`~pyspark.sql.Column` expression.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> df.select(when(df['age'] == 2, 3).otherwise(4).alias(\"age\")).collect()\n",
       "[Row(age=3), Row(age=4)]\n",
       "\n",
       ">>> df.select(when(df.age == 2, df.age + 1).alias(\"age\")).collect()\n",
       "[Row(age=3), Row(age=None)]\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/local/spark/python/pyspark/sql/functions.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "when?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ed2f99-49a8-4e0d-9176-0eef2fa50d69",
   "metadata": {},
   "source": [
    "# TASK\n",
    "\n",
    "Create a dataframe using list called as persons and categorize them based up on following rules.\n",
    "\n",
    "| Age range                | Category          |\n",
    "| -------------------------| ------------------|\n",
    "| 0 to 2 Months            | New Born          |\n",
    "| 2+ Months to 12 Months   | Infant            |\n",
    "|12+ Months to 48 Months   | Toddler           |\n",
    "| 48+ Months to 144 Months | Kids              |\n",
    "| 144+ Months              | Teenager or Adult |\n",
    "| -------------------------| ------------------|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a8402a53-e61a-4d0f-9519-2b4176a7edfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "persons = [\n",
    "    (1, 1),\n",
    "    (2, 13),\n",
    "    (3, 18),\n",
    "    (4, 60),\n",
    "    (5, 120),\n",
    "    (6, 0),\n",
    "    (7, 12),\n",
    "    (8, 160)\n",
    "]\n",
    "personsDF = spark.createDataFrame(persons, schema='id INT, age INT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c4911f2-f1fe-4240-8d64-1b033c99f2cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-----------------+\n",
      "| id|age|         category|\n",
      "+---+---+-----------------+\n",
      "|  1|  1|         New Born|\n",
      "|  2| 13|          Toddler|\n",
      "|  3| 18|          Toddler|\n",
      "|  4| 60|              Kid|\n",
      "|  5|120|              Kid|\n",
      "|  6|  0|         New Born|\n",
      "|  7| 12|           Infant|\n",
      "|  8|160|Teenager or Adult|\n",
      "+---+---+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "personsDF. \\\n",
    "    withColumn(\n",
    "        'category',\n",
    "        expr(\"\"\"\n",
    "            CASE\n",
    "            WHEN age BETWEEN 0 AND 2 THEN 'New Born'\n",
    "            WHEN age > 2 AND age <= 12 THEN 'Infant'\n",
    "            WHEN age > 12 AND age <= 48 THEN 'Toddler'\n",
    "            WHEN age > 48 AND age <= 144 THEN 'Kid'\n",
    "            ELSE 'Teenager or Adult'\n",
    "            END\n",
    "        \"\"\")\n",
    "    ). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20cd3ed7-980d-46e6-b5d8-0bd98e97dbfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-----------------+\n",
      "| id|age|         category|\n",
      "+---+---+-----------------+\n",
      "|  1|  1|         New Born|\n",
      "|  2| 13|          Toddler|\n",
      "|  3| 18|          Toddler|\n",
      "|  4| 60|              Kid|\n",
      "|  5|120|              Kid|\n",
      "|  6|  0|         New Born|\n",
      "|  7| 12|           Infant|\n",
      "|  8|160|Teenager or Adult|\n",
      "+---+---+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Another format\n",
    "personsDF. \\\n",
    "    withColumn(\n",
    "        'category',\n",
    "        when(col('age').between(0, 2), 'New Born').\n",
    "        when((col('age') > 2) & (col('age') <= 12), 'Infant').\n",
    "        when((col('age') > 12) & (col('age') <= 48), 'Toddler').\n",
    "        when((col('age') > 48) & (col('age') <= 144), 'Kid').\n",
    "        otherwise('Teenager or Adult')\n",
    "    ). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2994eb6-5e79-45cb-92b2-1acc0e6d8086",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
